---------------------------------------------------------------------------------------------------------------------------------------------
TODO list
---------------------------------------------------------------------------------------------------------------------------------------------
0/ Produce the Textual output  - December - Up to 12nd december:
    -Add the strain presence files



1/ Binary 2 continuous phenotype (December) - Up to 12nd december:
    -Step1: Accept continuous and N/A phenotype
        -Change the filter
        -Check if N/A works (see mail)
    -Step2: integrate it
        -already on the branch
    -Step3:
            -Color legend:
                -Legend: -> Estimated Effect
                -Pheno0: true minimum value
                -Pheno1: true maximum value
            -For the table, we replace Pheno0/Pheno1 -> Pheno <= Threshold and > Threshold
                -Threshold by default is 0, but should be a parameter
            -Step 3 should know and display the threshold



2/ Continuous Genotype (frequencies) - December - Up to 12nd december:
    -Step1:
        -Parameter that is binary or continuous (frequency) genotype
    -Step3:
        -Keep the binary version
        -Allele frequency





3/ Automated labelling prediction (December) - After 12nd December


4/ Custom Step2:
    -parameter: only run step1
    -customized step2 (script to run is a parameter, and we give all files to the scripts)
    -pyseer Step2
    -Other types of analysis
        -no analysis, fixed effect
        -bugwas bug




5/ Receive as input reads instead of contigs
    -BCALM2 + BTRIM
        -Filter on unitig count (check the parameter) and on kmer count  (-ab-min 2/3)
        -5 iterations of trimming





6/ Show the strain presence for each node
    -1st - just tabular export
    -Search for JS libraries or use iTol



7/ Step1:
    -Maf filter
    -Remove nodes with a given AF
    -Put in the docs that we count from genome assembly
    -Remove the filter that removes the genomes with missing phenotypes
    -Store patterns file as binary and/or sparse matrix format (many rows with many zeros)
        - if stores 0/1 values : would requireb Nstrain x Npatterns bits  




9/ Step3:
    -Layout with alongated nodes like Bandage



10/ Double-check SFF filter
    -When the 100th q-value is really not significant (like ~1), there is no meaning to generate a subgraph with the related unitigs.
    The double check would be: take the top 100 q-values below a threshold (like the usual 0.05). Do you think we could try this ?
    This would certainly lead to 2 different SFF parameters, which are somewhere correlated...



Integration with prokka
    @see https://gitlab.com/leoisl/dbgwas/issues/8



Next release (v0.5.2 ETA 31/05/2018):
Continuous genotypes/phenotypes:
    - Still read the phenotype as a string, to deal with NAs.
    - If not NA, convert to float, and store as a float in the strain object.
    - Replace the part where we test whether both "0" and "1" phenotypes are present by a test that the empirical variance of the phenotypes is above some threshold (or simply that they are not all identical).
    - Optionally build the pheno0Count and pheno1Count counters (which we use for visualization) using a user specified threshold: eg, users can say that positive phenotypes are class1 and non-negative ones are class 0. We provide a default threshold (eg >0 vs <=0, which works seamlessly for the current binary phenotypes) and an option to just desactivate the count columns in the visualization.
    Regarding the figures:
        - The barplot and manhattan plot for PCs can be done with non-binary phenotypes.
        - The "indiv vs first PCs" and tree plot would need to be adapted eg by replacing the 2 colors by a gradient of shades. I can try and do it (or we can just skip these plots for non-binary phenotypes for the moment).


Priority:
    1) Work on the javascript performance
        In very large graphs, selecting all nodes, unselecting, etc is very slow

    2) Change filter in the annotation list in the summary page (add option for the user to use text or to type something)
        In index pages with a lot of annotation, it is way too hard to use a drop-down list

    3) Do a text output of DBGWAS so users can use other tools to post-process its output
        -Implement https://gitlab.com/leoisl/dbgwas/issues/5

    5) Add to DBGWAS parameter -runOnlyStep1 Freq/Bin
        -It will just produces the variant matrices and stop
        -Freq = use frequences
        -Bin = use presence/absence pattern


    7) When launching only step3, there should be no need to specify a strain file

    8) Receive as input reads instead of contigs
        -@see https://mail.google.com/mail/u/0/#inbox/15ffcd92a248a692

    9) Treat NA phenotypes better
        -We just removed from the input for now

    10) "make" should copy the DBGWAS_lib folder to the tools/ folder

    11) Improve the explanation of lineage figures in the interface





Known bugs:
    -Large kmer size bug:
        -Even if we set in CMakeLists.txt:
            set (KSIZE_LIST "32   64   96  128  160  192  224  256")
        -We still can't run the tool with a large kmer size due to:
            leandro@ngs-provisoire:/data2/leandro/GWAS/DBGWAS-0.4.8-Linux-precompiled/bin$ ./DBGWAS -strains pseudomonas_aeruginosa_full_dataset/strains -newick pseudomonas_aeruginosa_full_dataset/strains.newick -nc_db Resistance_DB_for_DBGWAS.fasta -pt_db uniprot_sprot_bacteria_for_DBGWAS.with_extra_tags.fasta -nb-cores 4 -k 165 -output output_test_k_165
            Step 1. Building DBG and mapping strains on the DBG...
            [WARNING] Skipping strain WH-SGI-V-07286 because its phenotype is NA
            [WARNING] Skipping strain WH-SGI-V-07290 because its phenotype is NA
            [DSK: nb solid kmers found : 140764976   ]  100  %   elapsed:  12 min 3  sec   remaining:   0 min 0  sec   cpu: 153.4 %   mem: [ 924, 4598, 4598] MB
            [Building BooPHF]  99.8 %   elapsed:   0 min 57 sec   remaining:   0 min 0  sec
            [MPHF: populate                          ]  100  %   elapsed:   1 min 22 sec   remaining:   0 min 0  sec   cpu:  99.9 %   mem: [ 924,  924, 4598] MB
            EXCEPTION: kmer size 165 too big for cascading bloom filters
        -The maximum k-mer size we can use is 127
        -I am setting in CMakeLists.txt back to:
            set (KSIZE_LIST "32   64   96  128")

    -Fix copy and paste of cells containing annotation;
        -Asked on stack overflow

    -Bug with maf 0.5 => wrong node color (issue in step3)
        -@see https://mail.google.com/mail/u/0/#inbox/1600315d1c1fe7bc






Low priority TODO:
    -Select nodes using the newick tree
        -This is used to select nodes belonging to a strain
        -The newick tree should have only the strains that contains an unitig in the component
        -It should also show the strain path in the graph
    -Show the newick tree and the unitigs (genotypes)
        -@see: https://mail.google.com/mail/u/0/#sent/15f1663316ff5dec
  -Use a portable version of R to remove all dependencies?
  -Allow the user to provide an already built database, instead of calling makeblastdb always
  -Fix qvalue default min and max to min and max of the components
  -Use counts instead of pres/abs patterns for the genotypes (and one application would be to compute such analysis on transcriptome data);
  -Add covariates (e.g. patient metadata) in the association model;
  -If no annotation was provided, remove the line:
        Annotations on significant nodes:
        No annotations found.
    from the tables in the summary page
  -remove the patterns with maf < maf.filter in C++
    -ok for now (done in R)
  -Multiple alignment on the node sequences that are selected?
    -Maybe this allow us to run the MSA:
        -https://en.wikipedia.org/wiki/Asm.js
        -https://en.wikipedia.org/wiki/Emscripten
        -https://en.wikipedia.org/wiki/Google_Native_Client
    -To view the MSA, there are several JS plugins
        -http://msa.biojs.net/
    -Or do we need to implement MSA ourselves in javascript or run a local web server which will provide a way of calling a proper program to do this
  -Memory optimization:
    -Change UnitigIdStrandPos simply to unitigId
        -We just use the unitig id...
  -Transparency switch
    -Non-significant nodes lose transparency
  -Assemble the heaviest path of the DBG and blast it (or the path going through the largest number of significant unitigs)
    -I think we will need a good amount of effort here, and I do not know if it is an essential feature... To discuss...
  -Adding metadata to features (like what each genome mean, species, etc)
    -This would be a field in the input file with a collumn with whatever the user would like to put
    -Show the original genomes as paths in the graph?
  -Work on unitig counts rather than presence/absence




Suggestions from Magali's Formation:
-          Possibility to launch only step1. Thus, user can specify their own processing on the X matrix of unitigs.
-          Possibility to write a count matrix at step1, as we get this count value during step1.3. This would be useful for users designing their own step2 (all the trainees were bioinformaticians/biostatisticians)
-          Possibility to map a particular sequence on the output subgraphs (highlight its path). This is a little bit different from the mapping of a complete input individual sequence. Here, the idea would be to “visualize” on the graph a particular gene variant. Indeed, a lot of resistance genes are gene family containing well described and well annotated variant. For instance, when we see than 44 nodes got the “TEM-11” annotation, the idea would be to draw the (real exact) path of TEM-11 sequence on the graph…
-          Possibility to export graph view as bitmap…
-          Possibility to export linear paths as patterns of sequences




Other discussions from Magali's Formation:
 When discuting about newick files creation:
-          multiple alignment of core genes. The core gene collection creation, and the (manual) cleaning of multiple alignment can take really a lot of time and can require quite a lot of expertise
-          MLST schemes. These are list of predefined genes seen as allele, and the distance between 2 strains is computed as the number of differing alleles the strains get (thus is both gene differ by 1 or 100 SNPs, the distance for this allele will be 1). This take the accessory MLST gene into account. This required that a MLST scheme is available for the species. It is not always/often the case, but when it exists, this is less time-consuming than building core gene alignments.
-          Kmer-bases phylogeny. I wondered if it already exists and if it could make sense to phylogeneticians. Apparently yes, and for at least 5 years: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0081760  and https://academic.oup.com/bioinformatics/article-pdf/31/17/2877/445523/btv271.pdf

