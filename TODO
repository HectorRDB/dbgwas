To check:
    -Fixed a small bug on the annotation filtering in the index page (genes between parenthesis)


High priority TODO:
  -Make the annotation process optional and also check if blastn is on the path
    -Or we can also pack blastn and makeblastdb in the app
        -This can be good since then we enforce the blast and makeblast versions... And that is additional 50 MBs
  -Allow users to input their own annotation database (Christine's example)
    -The problem is the standardization on FASTA headers... I guess if we do this, we should not force the users to standardize it
        -We can define two TAGs on the fasta header:
            -DBGWAS_index_tag=<value>
            -DBGWAS_graph_tag=<value>
        which is what is going to be shown on the index and graph pages. If these tags are not found in the header, then we just set both values to the full header.
        This way people can provide their own database, and they customize it or not...
    -Maybe with this we won't need to blast to online database - the annotation is as good as the database provided by the user...
  -Show other info output by blast on the index page/graph page?
    -Order the genes by these info?
  -Fix the error we get when the filter has no rules in the index page
  -Write the nb of significant patterns and significant unitigs in the index page
    -Maybe just show all the arguments of the execution
  -Show the original genomes as paths in the graph?
  -newick file should be optional (R script and software)
  -remove the patterns with maf < maf.filter in C++
  -treat NA better
  -svd and pca steps are probably redundant in cdbg_lin_loc as XX is centered. Check that they produce the same set of eigenvectors and remove the pca steps (call to prcomp uses more memory than svd).
  -fix output folder from being fixed to being a parameter
      -Need a fix on Gemma/Bugwas output folder first


Low priority TODO:
  - When the strains input file is missing, we return an error:
      [FATAL ERROR] Error opening file
      Could it be a little more detailed? Eg, which file (there are two inputs), and whether the format is wrong or the file was not found.
  - possibility to work on unitig counts rather than presence/absence
  - memory bottleneck right now when do.lineage=TRUE is in computing the correlations between all PCs and variants. Could be improved but not trivial. Second bottleneck is in computing SVD.









Misc:
Installing zlib (only for compiling):
   sudo apt-get install libgcrypt11-dev zlib1g-dev
